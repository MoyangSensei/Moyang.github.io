<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><meta name="author" content="Fy J"><meta name="renderer" content="webkit"><meta name="copyright" content="Fy J"><meta name="keywords" content="MoyangSensei"><meta name="description" content="null"><meta name="Cache-Control" content="no-cache"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><title>社会媒体计算：知乎问答信息挖掘 · MoYang</title><link rel="stylesheet" href="/css/style.css?v=2018.7.9"><link rel="stylesheet" href="/css/animation.css?v=2018.7.9"><link rel="icon" href="/img/assets/Moyangico.ico"><link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css?version=1.5.6"><!-- scripts--><script>(function( w ){
  "use strict";
  // rel=preload support test
  if( !w.loadCSS ){
    w.loadCSS = function(){};
  }
  // define on the loadCSS obj
  var rp = loadCSS.relpreload = {};
  // rel=preload feature support test
  // runs once and returns a function for compat purposes
  rp.support = (function(){
    var ret;
    try {
      ret = w.document.createElement( "link" ).relList.supports( "preload" );
    } catch (e) {
      ret = false;
    }
    return function(){
      return ret;
    };
  })();

  // if preload isn't supported, get an asynchronous load by using a non-matching media attribute
  // then change that media back to its intended value on load
  rp.bindMediaToggle = function( link ){
    // remember existing media attr for ultimate state, or default to 'all'
    var finalMedia = link.media || "all";

    function enableStylesheet(){
      link.media = finalMedia;
    }

    // bind load handlers to enable media
    if( link.addEventListener ){
      link.addEventListener( "load", enableStylesheet );
    } else if( link.attachEvent ){
      link.attachEvent( "onload", enableStylesheet );
    }

    // Set rel and non-applicable media type to start an async request
    // note: timeout allows this to happen async to let rendering continue in IE
    setTimeout(function(){
      link.rel = "stylesheet";
      link.media = "only x";
    });
    // also enable media after 3 seconds,
    // which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
    setTimeout( enableStylesheet, 3000 );
  };

  // loop through link elements in DOM
  rp.poly = function(){
    // double check this to prevent external calls from running
    if( rp.support() ){
      return;
    }
    var links = w.document.getElementsByTagName( "link" );
    for( var i = 0; i < links.length; i++ ){
      var link = links[ i ];
      // qualify links to those with rel=preload and as=style attrs
      if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
        // prevent rerunning on link
        link.setAttribute( "data-loadcss", true );
        // bind listeners to toggle media back
        rp.bindMediaToggle( link );
      }
    }
  };

  // if unsupported, run the polyfill
  if( !rp.support() ){
    // run once at least
    rp.poly();

    // rerun poly on an interval until onload
    var run = w.setInterval( rp.poly, 500 );
    if( w.addEventListener ){
      w.addEventListener( "load", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    } else if( w.attachEvent ){
      w.attachEvent( "onload", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    }
  }


  // commonjs
  if( typeof exports !== "undefined" ){
    exports.loadCSS = loadCSS;
  }
  else {
    w.loadCSS = loadCSS;
  }
}( typeof global !== "undefined" ? global : this ) );</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" defer></script><script src="/js/main.js?v=2018.7.9" defer></script><!-- fancybox--><link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script><!-- busuanzi--><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta name="generator" content="Hexo 5.1.1"><link rel="alternate" href="/atom.xml" title="MoyangSensei" type="application/atom+xml">
</head><body><section class="profile-close" id="cxo-profile"><div class="profile-avatar"><i class="fa fa-caret-left"></i><img src="/img/assets/cat.png"></div><!--.profile-saying
  i.fa.fa-comment
  .saying--><div class="cxo-profile-inner"><div class="profile-name">Fy J</div><div class="profile-signature">CS专业扫雷学深造学者互联网冲浪一级选手</div><div class="friends"><div>FRIENDS</div><span><a href="//hnjia00.github.io" target="_black">jhn</a></span></div><div class="read-progress"></div></div></section><header id="cxo-intro" style="height: 70vh;background-image: url(/img/intro/index-bg.png);"><nav id="cxo-intro-nav"><section><div class="intro-nav-title"><a href="/">MoYang's Blog</a></div><div class="intro-nav-label-box"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div><i class="fa fa-bars intro-nav-menu"><div class="intro-nav-drop"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div></i><div class="clear"></div></section></nav><h1 class="post-title">社会媒体计算：知乎问答信息挖掘</h1><div class="post-intros"><div class="post-intro-meta"><span class="post-intro-time"><i class="post-intro-calendar fa fa-calendar"></i><span>04-14-2021 15:33:25</span></span><span class="post-intro-tags"><a class="intro-tag fa fa-tag" href="javascript:void(0)" date-tags="社会媒体计算"> 社会媒体计算</a></span></div><div class="post-intro-read"><span> Word count: <span class="post-count">3.8k</span> | Reading time: <span class="post-count">17</span>min</span></div></div></header><article class="cxo-up" id="cxo-content-outer"><section id="cxo-content-inner"><article class="article-entry" id="post"><blockquote>
<p>原创文章，转载、引用请注明出处！</p>
</blockquote>
<hr>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>刚好在摸鱼的时候比较喜欢刷知乎，又碰到了这个课程，所以就尝试了做这个内容。以前从来没有接触过文本分析和爬虫这类的技术，就当学新技术了。以及这些在去年12月就写完了，现在闲了才想起搬到这里来。</p>
<p>依稀记得那是为数不多的有心思敲代码的时间，会珍惜的。</p>
<hr>
<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><h2 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h2><p>从互联网上采集数据，如从 Tewitter、Facebook、新浪微博、B站等采集数据，包括用户基本信息、互相浏览、互相关注等信息，以及对应某一段时间发布的文本内容信息。</p>
<p>对上述数据进行预处理，要求用程序进行预处理。</p>
<p>对上述处理数据进行社团挖掘，包括基本统计信息、社团发现等，对预处理的文本进行情感分析、主题挖掘、分类或聚类等研究。要求用到社会网络计算、文本挖掘等技术。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>知乎是一个网络问答社区，用户彼此分享知识、经验和见解，围绕着某一感兴趣的话题进行相关的讨论，同时也可以关注兴趣一致的人。</p>
<p>知乎的基本模式是：用户提问，每一个问题都会有一个独有的id。其他对此问题感兴趣的用户在此问题下进行回答，每一个此问题下的回答也会有一个id。用户可对回答进行点赞、点踩、评论等操作。</p>
<p>选择从知乎采集要用到的数据。所选取的问题是：你打算在 12 月 31 日发什么朋友圈跨年文案？</p>
<p>链接：<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/360940960">https://www.zhihu.com/question/360940960</a></p>
<p><img src="/images/%E7%A4%BE%E4%BC%9A%E5%AA%92%E4%BD%93%E8%AE%A1%E7%AE%97/1.png" title="Optional title"></p>
<h2 id="编程环境"><a href="#编程环境" class="headerlink" title="编程环境"></a>编程环境</h2><p>Mac OS 10.14.6 + Jupyter notebook + Python 3.6.5</p>
<h1 id="知乎数据采集"><a href="#知乎数据采集" class="headerlink" title="知乎数据采集"></a>知乎数据采集</h1><h2 id="数据爬虫"><a href="#数据爬虫" class="headerlink" title="数据爬虫"></a>数据爬虫</h2><p>这部分爬虫功能的主要作用就是从知乎的网页上拿数据。</p>
<p><strong>这部分的原理参考最下面唯一的一条引用，包括从网络请求找到数据存放位置、分析请求头的格式和构造代码中所需要的新的请求头。</strong></p>
<p>def crawler(question_num)是该部分功能的组织函数，其他4个函数的具体功能见注释。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span>(<span class="params">url</span>):</span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#     功能：访问 url 的网页，获取网页内容并返回</span></span><br><span class="line"><span class="comment">#     参数：</span></span><br><span class="line"><span class="comment">#         url ：目标网页的 url</span></span><br><span class="line"><span class="comment">#     返回：目标网页的 html 内容</span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 设置多个用户代理</span></span><br><span class="line">    agent=[<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.80 Safari/537.36&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:30.0) Gecko/20100101 Firefox/30.0&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/537.75.14&#x27;</span>,  </span><br><span class="line">    <span class="string">&#x27;Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Win64; x64; Trident/6.0)&#x27;</span> ]</span><br><span class="line">    <span class="comment"># 每次随机抽取一个，防止被封ip</span></span><br><span class="line">    randdom_agent=random.choice(agent)</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;user-agent&#x27;</span>: randdom_agent</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 爬取数据</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        r = requests.get(url, headers=headers)</span><br><span class="line">        r.encoding = <span class="string">&#x27;UTF8&#x27;</span></span><br><span class="line">        r.raise_for_status()</span><br><span class="line">        <span class="keyword">return</span> r.text</span><br><span class="line">    <span class="keyword">except</span> requests.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line">        print(<span class="string">&quot;HTTPError&quot;</span>)</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        print(<span class="string">&quot;Unknown Error !&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_data</span>(<span class="params">html</span>):</span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#     功能：提取 html 页面信息中的关键信息，并整合一个数组并返回</span></span><br><span class="line"><span class="comment">#     参数：</span></span><br><span class="line"><span class="comment">#         html：根据 url 获取到的网页内容</span></span><br><span class="line"><span class="comment">#     返回：存储有 html 中提取出的关键信息的数组</span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;</span></span><br><span class="line">    json_data = json.loads(html)[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">    comments = []</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> json_data:</span><br><span class="line">            comment = []</span><br><span class="line">            comment.append(item[<span class="string">&#x27;author&#x27;</span>][<span class="string">&#x27;name&#x27;</span>]) <span class="comment"># 姓名</span></span><br><span class="line">            comment.append(item[<span class="string">&#x27;author&#x27;</span>][<span class="string">&#x27;gender&#x27;</span>]) <span class="comment"># 性别</span></span><br><span class="line">            comment.append(item[<span class="string">&#x27;voteup_count&#x27;</span>]) <span class="comment"># 点赞数</span></span><br><span class="line">            comment.append(item[<span class="string">&#x27;comment_count&#x27;</span>])  <span class="comment"># 评论数</span></span><br><span class="line">            comment.append(item[<span class="string">&#x27;url&#x27;</span>])  <span class="comment"># 回答链接</span></span><br><span class="line">            comment.append(item[<span class="string">&#x27;created_time&#x27;</span>])  <span class="comment"># 回答时间</span></span><br><span class="line">            comment.append(item[<span class="string">&#x27;content&#x27;</span>]) <span class="comment"># 回答时间</span></span><br><span class="line">            comments.append(comment)   </span><br><span class="line">        <span class="keyword">return</span> comments    </span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(comment)</span><br><span class="line">        print(e)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_file</span>(<span class="params">question_num</span>):</span></span><br><span class="line"><span class="comment">#      &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#     功能：根据知乎的问题id构造文件路径和文件名，csv、png都会用到</span></span><br><span class="line"><span class="comment">#     参数：</span></span><br><span class="line"><span class="comment">#         question_num：知乎提问的问题id</span></span><br><span class="line"><span class="comment">#     返回：csv文件路径、csv文件名</span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;</span></span><br><span class="line">    current_path = os.getcwd()</span><br><span class="line">    file_name=str(question_num)+<span class="string">&#x27;_&#x27;</span>+str(datetime.datetime.now())+<span class="string">&#x27;.csv&#x27;</span></span><br><span class="line">    path = current_path+<span class="string">&#x27;/&#x27;</span>+file_name</span><br><span class="line">    print(<span class="string">&quot;文件：&quot;</span>+path)</span><br><span class="line">    <span class="keyword">return</span> path,file_name</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_data</span>(<span class="params">comments,header,path</span>):</span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#     功能：将comments中的信息输出到文件/数据库中</span></span><br><span class="line"><span class="comment">#     参数：</span></span><br><span class="line"><span class="comment">#         comments：将要保存的数据  </span></span><br><span class="line"><span class="comment">#     返回：无</span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataframe = pd.DataFrame(comments)</span><br><span class="line">    <span class="keyword">if</span> header:</span><br><span class="line">        dataframe.to_csv(path, mode=<span class="string">&#x27;a&#x27;</span>, index=<span class="literal">False</span>, sep=<span class="string">&#x27;,&#x27;</span>, header=[<span class="string">&#x27;name&#x27;</span>,<span class="string">&#x27;gender&#x27;</span>,<span class="string">&#x27;voteup&#x27;</span>,<span class="string">&#x27;cmt_count&#x27;</span>,<span class="string">&#x27;ans_url&#x27;</span>,<span class="string">&#x27;ans_time&#x27;</span>,<span class="string">&#x27;ans_content&#x27;</span>])</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dataframe.to_csv(path, mode=<span class="string">&#x27;a&#x27;</span>, index=<span class="literal">False</span>, sep=<span class="string">&#x27;,&#x27;</span>, header=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawler</span>(<span class="params">question_num</span>):</span></span><br><span class="line"><span class="comment">#      &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#     功能：爬虫功能的组织函数，爬取数据并存储到csv文件中</span></span><br><span class="line"><span class="comment">#     参数：</span></span><br><span class="line"><span class="comment">#         question_num：知乎提问的问题id</span></span><br><span class="line"><span class="comment">#     返回：文件名</span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;</span></span><br><span class="line">    url_start = <span class="string">&#x27;https://www.zhihu.com/api/v4/questions/&#x27;</span>+str(question_num)+<span class="string">&#x27;/answers?include=data%5B%2A%5D.is_normal%2Cadmin_closed_comment%2Creward_info%2Cis_collapsed%2Cannotation_action%2Cannotation_detail%2Ccollapse_reason%2Cis_sticky%2Ccollapsed_by%2Csuggest_edit%2Ccomment_count%2Ccan_comment%2Ccontent%2Ceditable_content%2Cvoteup_count%2Creshipment_settings%2Ccomment_permission%2Ccreated_time%2Cupdated_time%2Creview_info%2Crelevant_info%2Cquestion%2Cexcerpt%2Crelationship.is_authorized%2Cis_author%2Cvoting%2Cis_thanked%2Cis_nothelp%2Cis_labeled%3Bdata%5B%2A%5D.mark_infos%5B%2A%5D.url%3Bdata%5B%2A%5D.author.follower_count%2Cbadge%5B%2A%5D.topics&amp;limit=5&amp;offset=&#x27;</span></span><br><span class="line">    url_end=<span class="string">&#x27;&amp;platform=desktop&amp;sort_by=default&#x27;</span></span><br><span class="line">    html=get_data(url_start+str(<span class="number">5</span>)+url_end)</span><br><span class="line">    totals=json.loads(html)[<span class="string">&#x27;paging&#x27;</span>][<span class="string">&#x27;totals&#x27;</span>]</span><br><span class="line">    path,file_name=get_file(question_num)</span><br><span class="line">    </span><br><span class="line">    print(<span class="string">&quot;总回答数：&quot;</span>+str(totals))</span><br><span class="line">    page = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span>(page &lt; totals):</span><br><span class="line">        url = url_start+str(page) +url_end</span><br><span class="line"> </span><br><span class="line">        html = get_data(url)</span><br><span class="line">        comments = parse_data(html)</span><br><span class="line">        <span class="keyword">if</span> page==<span class="number">0</span>:</span><br><span class="line">            save_data(comments,<span class="literal">True</span>,path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            save_data(comments,<span class="literal">False</span>,path)</span><br><span class="line">        page += <span class="number">5</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> file_name</span><br></pre></td></tr></table></figure>

<h2 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h2><p>def save_data(comments,header,path)将爬到的数据存到了.CSV中，数据读取函数则将CSV中的内容读到内存里供。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_csv</span>(<span class="params">file_name</span>):</span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#     功能：读取爬虫函数得到的csv文件</span></span><br><span class="line"><span class="comment">#     参数：</span></span><br><span class="line"><span class="comment">#         file_name：文件名  </span></span><br><span class="line"><span class="comment">#     返回：csv文件的list</span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> open(file_name, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        reader = csv.reader(f)</span><br><span class="line">        result = list(reader)</span><br><span class="line">        <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>

<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>爬取下来的数据需要预处理。<strong>主要是因为所关注的“ans_content”内，除了中文之外，还有一些奇奇怪怪的东西</strong>：</p>
<p><img src="/images/%E7%A4%BE%E4%BC%9A%E5%AA%92%E4%BD%93%E8%AE%A1%E7%AE%97/2.png" title="Optional title"></p>
<p>可以看到，<strong>有emoji、有非中文的特殊字符、有h5的标签</strong>（由&lt;&gt;括起的部分，主要由于回答中的图片的网页链接需要用这种方式在网页源码内引用）。<strong>使用正则表达式去掉这些对中文文本分析没有用的内容。</strong></p>
<p>其他的一些处理还包括<strong>秒级时间戳的转换和知乎用户系统中的“匿名用户”进行编号等</strong>。这些无关紧要，只是为了看着舒服。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">date_pre_treatment</span>(<span class="params">csv_data</span>):</span></span><br><span class="line"><span class="comment">#      &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#     功能：数据预处理</span></span><br><span class="line"><span class="comment">#     参数：</span></span><br><span class="line"><span class="comment">#         csv_data：已经读取好的list  </span></span><br><span class="line"><span class="comment">#     返回：经过了预处理的list</span></span><br><span class="line"><span class="comment">#     &#x27;&#x27;&#x27;</span></span><br><span class="line">    niming_num=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(csv_data[<span class="number">0</span>])):</span><br><span class="line">        <span class="keyword">if</span> csv_data[<span class="number">0</span>][j]==<span class="string">&#x27;name&#x27;</span>:</span><br><span class="line">            <span class="keyword">for</span> i1 <span class="keyword">in</span> range(len(csv_data)):</span><br><span class="line">                <span class="comment"># 将知乎用户、匿名用户的名称统一，加上编号做区分</span></span><br><span class="line">                <span class="keyword">if</span> csv_data[i1][j]==<span class="string">&#x27;知乎用户&#x27;</span> <span class="keyword">or</span> csv_data[i1][j]==<span class="string">&#x27;匿名用户&#x27;</span>:</span><br><span class="line">                    csv_data[i1][j]=<span class="string">&#x27;匿名用户&#x27;</span>+str(++niming_num)</span><br><span class="line">        <span class="keyword">if</span> csv_data[<span class="number">0</span>][j]==<span class="string">&#x27;ans_time&#x27;</span>:</span><br><span class="line">            <span class="keyword">for</span> i2 <span class="keyword">in</span> range(len(csv_data)<span class="number">-1</span>):</span><br><span class="line">                ltime = time.localtime(int(csv_data[i2+<span class="number">1</span>][j]))</span><br><span class="line">                <span class="comment"># 将秒级时间戳转化为&quot;年月日时分秒&quot;格式</span></span><br><span class="line">                csv_data[i2+<span class="number">1</span>][j]=time.strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>,ltime)</span><br><span class="line">        <span class="keyword">if</span> csv_data[<span class="number">0</span>][j]==<span class="string">&#x27;ans_content&#x27;</span>:</span><br><span class="line">            <span class="keyword">for</span> i3 <span class="keyword">in</span> range(len(csv_data)):</span><br><span class="line">                <span class="comment"># 去除文本信息中的h5标签</span></span><br><span class="line">                csv_data[i3][j] = re.sub(<span class="string">u&quot;\\&lt;.*?\\&gt;&quot;</span>, <span class="string">&quot; &quot;</span>, csv_data[i3][j])</span><br><span class="line">                <span class="comment"># 去除文本信息除中文、英文、ascll字符、常用标点以外的所有内容</span></span><br><span class="line">                csv_data[i3][j] = re.sub(<span class="string">&quot;[^\u4e00-\u9fa5 ^a-z ^A-Z ^0-9 ^~!@#$%&amp;*()_+-=:;,.^～！，。？、《》]&quot;</span>,<span class="string">&#x27;&#x27;</span>, csv_data[i3][j])</span><br><span class="line">        <span class="keyword">if</span> csv_data[<span class="number">0</span>][j]==<span class="string">&#x27;voteup&#x27;</span>:</span><br><span class="line">            <span class="keyword">for</span> i4 <span class="keyword">in</span> range(len(csv_data)<span class="number">-1</span>):</span><br><span class="line">                <span class="comment"># 将投票数转化为int（读取的时候会存储为str）</span></span><br><span class="line">                csv_data[i4+<span class="number">1</span>][j] = int(float(csv_data[i4+<span class="number">1</span>][j]))</span><br><span class="line">    <span class="keyword">return</span> csv_data</span><br></pre></td></tr></table></figure>

<p><img src="/images/%E7%A4%BE%E4%BC%9A%E5%AA%92%E4%BD%93%E8%AE%A1%E7%AE%97/3.png" title="Optional title"></p>
<h1 id="词云"><a href="#词云" class="headerlink" title="词云"></a>词云</h1><p>使用wordcloud包进行所有回答文本的词云的绘制，并存储为png图片文件。用到的功能为WordCloud，参数和说明见代码注释。</p>
<p><strong>词云的图如果想做的有意义且好看，最主要的参数是stopwords、max_words。</strong></p>
<p>其中，stopwords指的是词云里什么词不能出现，默认为空。毕竟不管是中文还是英文，文本里都有许多没有意义的词，比如语气词“嗯”、“啊”、“呢”这种类似的。所以如果不加限制的话，词云里最大的那个词一定是没什么意义的词（知乎作为一个网络社区，大家的回答肯定是偏向口头语的，那么无意义的词就会多起来，毕竟没人在知乎上写论文是吧）。这里的stopwords是通过txt导入的。stopwords网上能找到许多，我是在GitHub上找到了一份中文停用词，直接拿过来用了。后期又在里面填了一些自己不想看见的词。</p>
<p>max_words就是图片上最多出现多少个词，个人感觉还是多一些好看。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line">now_time= datetime.datetime.now()</span><br><span class="line">print(<span class="string">&quot;2.词云&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置数据，将所有文本放到一个list里方便处理</span></span><br><span class="line">text = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(csv_data)<span class="number">-1</span>):</span><br><span class="line">    text+=csv_data[i+<span class="number">1</span>][<span class="number">6</span>]+<span class="string">&#x27; &#x27;</span></span><br><span class="line"><span class="comment"># 结巴中文分词，生成字符串，默认精确模式，如果不通过分词，无法直接生成正确的中文词云</span></span><br><span class="line">cut_text = jieba.cut(text)</span><br><span class="line"><span class="comment"># 必须给个符号分隔开分词结果来形成字符串,否则不能绘制词云</span></span><br><span class="line">result = <span class="string">&quot; &quot;</span>.join(cut_text)</span><br><span class="line"><span class="comment"># 从文件中获取停用词</span></span><br><span class="line">stopwords=get_stopwords()</span><br><span class="line"><span class="comment"># 词云设置</span></span><br><span class="line">wc = WordCloud(     </span><br><span class="line">        font_path=<span class="string">&quot;仿宋_GB2312.ttf&quot;</span>,<span class="comment"># 设置字体（不指定就会出现乱码）</span></span><br><span class="line">        background_color=<span class="string">&#x27;white&#x27;</span>,<span class="comment"># 设置背景色</span></span><br><span class="line">        width=<span class="number">1500</span>, height=<span class="number">900</span>,<span class="comment"># 设置背景宽、高</span></span><br><span class="line">        max_font_size=<span class="number">400</span>, min_font_size=<span class="number">20</span>,<span class="comment"># 设置字体大小上下限</span></span><br><span class="line">        stopwords = stopwords,<span class="comment"># 停用词</span></span><br><span class="line">        max_words=<span class="number">150</span> <span class="comment"># 图片中显示词的最大数量</span></span><br><span class="line">        )</span><br><span class="line"><span class="comment"># 产生词云</span></span><br><span class="line">wc.generate(result)</span><br><span class="line"><span class="comment"># 保存图片</span></span><br><span class="line">pic_name=re.sub(<span class="string">&#x27;.csv&#x27;</span>,<span class="string">&#x27;&#x27;</span>,file_name)+<span class="string">&#x27;_wordcloud.png&#x27;</span></span><br><span class="line">wc.to_file(pic_name) </span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">10</span>))</span><br><span class="line">plt.imshow(wc)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Runtime:%d s&#x27;</span>%(datetime.datetime.now()-now_time).seconds)</span><br></pre></td></tr></table></figure>

<p><img src="/images/%E7%A4%BE%E4%BC%9A%E5%AA%92%E4%BD%93%E8%AE%A1%E7%AE%97/4.png" title="Optional title"></p>
<h1 id="keywords"><a href="#keywords" class="headerlink" title="keywords"></a>keywords</h1><p>使用jieba包进行关键词提取。</p>
<p>Jieba提供了两种关键词的提取算法，分别是：</p>
<ul>
<li><p>基于TF-IDF（term frequency–inverse document frequency）算法的关键词抽取。函数参数如下：sentence：待提取的文本；topK：返回topK个 TF/IDF 权重最大的关键词；withWeight：是否一并返回关键词权重值，默认值为False；allowPOS：仅包括指定词性的词，默认值为空，即不筛选。</p>
</li>
<li><p>基于TextRank算法的关键词抽取。函数接口同TF-IDF相同。不同的是allowPOS默认指定了一些词性的词。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line">now_time= datetime.datetime.now()</span><br><span class="line">print(<span class="string">&quot;3.keywords&quot;</span>)</span><br><span class="line">print(<span class="string">&quot;3.1. TF-IDF&quot;</span>)</span><br><span class="line">keywords1=jieba.analyse.extract_tags(text, topK=<span class="number">20</span>, withWeight=<span class="literal">True</span>, allowPOS=(<span class="string">&#x27;ns&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;vn&#x27;</span>, <span class="string">&#x27;v&#x27;</span>))</span><br><span class="line">print(keywords1)</span><br><span class="line">print(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">print(<span class="string">&quot;3.2. textrank&quot;</span>)</span><br><span class="line">keywords2=jieba.analyse.textrank(text, topK=<span class="number">20</span>, withWeight=<span class="literal">True</span>, allowPOS=(<span class="string">&#x27;ns&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;vn&#x27;</span>, <span class="string">&#x27;v&#x27;</span>)) </span><br><span class="line">print(keywords2)</span><br><span class="line">print(<span class="string">&#x27;Runtime:%d s&#x27;</span>%(datetime.datetime.now()-now_time).seconds)</span><br></pre></td></tr></table></figure>

<p><img src="/images/%E7%A4%BE%E4%BC%9A%E5%AA%92%E4%BD%93%E8%AE%A1%E7%AE%97/5.png" title="Optional title"></p>
<h1 id="情感分析"><a href="#情感分析" class="headerlink" title="情感分析"></a>情感分析</h1><p>使用snownlp进行情感分析。</p>
<p>snownlp是一个python类库，可以方便的处理中文文本内容，是受到了TextBlob的启发而写的，并且和TextBlob不同的是，这里没有用NLTK，所有的算法都是重新实现的，并且自带了一些训练好的字典。</p>
<blockquote>
<p>snownlp: <a target="_blank" rel="noopener" href="https://github.com/isnowfy/snownlp">https://github.com/isnowfy/snownlp</a><br>TextBlob: <a target="_blank" rel="noopener" href="https://github.com/sloria/TextBlob">https://github.com/sloria/TextBlob</a></p>
</blockquote>
<p><strong>snownlp给出了基于贝叶斯分类的情感分析函数SnowNLP。对于每一条文本，该函数会给出一个0-1之间的评分，越接近1代表积极情绪占比越高。</strong></p>
<p>使用SnowNLP对每一条回答文本进行情感分析，并以评分达到<strong>0.6、0.5认定为是积极文本</strong>，分别给出积极回答文本在所有文本中的比重。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> snownlp <span class="keyword">import</span> SnowNLP</span><br><span class="line">now_time= datetime.datetime.now()</span><br><span class="line">print(<span class="string">&quot;4.情感分析&quot;</span>)</span><br><span class="line">s=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(csv_data)<span class="number">-1</span>):</span><br><span class="line">    a=SnowNLP(csv_data[i+<span class="number">1</span>][<span class="number">6</span>])</span><br><span class="line">    s.append(round(a.sentiments,<span class="number">3</span>))</span><br><span class="line">s.sort(reverse=<span class="literal">True</span>)</span><br><span class="line">flag06=<span class="number">-1</span></span><br><span class="line">flag05=<span class="number">-1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(s)):</span><br><span class="line">    <span class="keyword">if</span> s[i]&lt;<span class="number">0.5</span> :</span><br><span class="line">        flag05=i</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(s)):</span><br><span class="line">    <span class="keyword">if</span> s[i]&lt;<span class="number">0.6</span> :</span><br><span class="line">        flag06=i</span><br><span class="line">        <span class="keyword">break</span>    </span><br><span class="line">print(<span class="string">&quot;积极（60%）百分比：&quot;</span>,round(flag06/(len(s)),<span class="number">2</span>)) </span><br><span class="line">print(<span class="string">&quot;积极（50%）百分比：&quot;</span>,round(flag05/(len(s)),<span class="number">2</span>))         </span><br><span class="line">print(<span class="string">&#x27;Runtime:%d s&#x27;</span>%(datetime.datetime.now()-now_time).seconds)</span><br></pre></td></tr></table></figure>

<p><img src="/images/%E7%A4%BE%E4%BC%9A%E5%AA%92%E4%BD%93%E8%AE%A1%E7%AE%97/6.png" title="Optional title"></p>
<p><strong>两个评分阈值下的大部分的回答都被认为是积极的，这也符合这个问题的背景：新年。</strong></p>
<h1 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h1><p>对点赞数最多的100条数据进行聚类。</p>
<p>进行涉及文本的向量化表示。sklearn提供了传统的词袋模型。使用sklearn中的TfidfVectorizer计算tf-idf矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> operator <span class="keyword">import</span> itemgetter</span><br><span class="line">print(<span class="string">&#x27;5. 文本聚类&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;5.1. 准备点赞数最多的100条数据&#x27;</span>)</span><br><span class="line">user_id=[]</span><br><span class="line">content=[]</span><br><span class="line">csv_data_sorted=csv_data</span><br><span class="line"><span class="keyword">del</span>(csv_data_sorted[<span class="number">0</span>])</span><br><span class="line">csv_data_sorted=sorted(csv_data,key=itemgetter(<span class="number">2</span>))</span><br><span class="line"><span class="comment"># print(csv_data[:10])</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    user_id.append(csv_data_sorted[i][<span class="number">0</span>])</span><br><span class="line">    content.append(csv_data_sorted[i][<span class="number">6</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line">now_time= datetime.datetime.now()</span><br><span class="line">print(<span class="string">&#x27;5.2. tfidf matrix&#x27;</span>)</span><br><span class="line"><span class="comment">#max_df: When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</span></span><br><span class="line"><span class="comment">#min_df: When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.</span></span><br><span class="line">tfidf_vectorizer = TfidfVectorizer(max_df=<span class="number">0.9</span>, max_features=<span class="number">200000</span>,min_df=<span class="number">0.1</span>, stop_words=<span class="string">&#x27;english&#x27;</span>,use_idf=<span class="literal">True</span>, tokenizer=segment)</span><br><span class="line">tfidf_matrix = tfidf_vectorizer.fit_transform(content) <span class="comment">#fit the vectorizer to synopses</span></span><br><span class="line">print(tfidf_matrix.shape)</span><br><span class="line">print(<span class="string">&#x27;Runtime:%d s&#x27;</span>%(datetime.datetime.now()-now_time).seconds)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> ward, dendrogram, linkage</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line">now_time= datetime.datetime.now()</span><br><span class="line">print(<span class="string">&#x27;5.3. linkage matrix&#x27;</span>)</span><br><span class="line">dist = <span class="number">1</span> - cosine_similarity(tfidf_matrix)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;Microsoft YaHei&#x27;</span>] <span class="comment">#用来正常显示中文标签</span></span><br><span class="line">linkage_matrix = linkage(dist, method=<span class="string">&#x27;ward&#x27;</span>, metric=<span class="string">&#x27;euclidean&#x27;</span>, optimal_ordering=<span class="literal">False</span>)</span><br><span class="line">print(<span class="string">&#x27;Runtime:%d s&#x27;</span>%(datetime.datetime.now()-now_time).seconds)</span><br><span class="line">print(linkage_matrix)</span><br></pre></td></tr></table></figure>

<p>由于选取了100条回答，tf-idf矩阵的第一维为100。</p>
<p>然后根据tf-idf矩阵进行层次聚类，给出linkage矩阵。使用函数：scipy.cluster.hierarchy.linkage(y, method=’single’, metric=’euclidean’, optimal_ordering=False)。其中，计算新形成的聚类簇u和v之间距离的方法是用的是single，即最近邻点算法。</p>
<p><img src="/images/%E7%A4%BE%E4%BC%9A%E5%AA%92%E4%BD%93%E8%AE%A1%E7%AE%97/7.png" title="Optional title"></p>
<p>对上述矩阵进行可视化，并将结果保存为png文件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">now_time= datetime.datetime.now()</span><br><span class="line">print(<span class="string">&#x27;5.4. linkage matrix可视化&#x27;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">40</span>, <span class="number">15</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;层次聚类树状图&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;知乎用户名称&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;距离（越低表示文本越类似）&#x27;</span>)</span><br><span class="line">dendrogram(</span><br><span class="line">    linkage_matrix,</span><br><span class="line">    labels=user_id, </span><br><span class="line">    leaf_rotation=<span class="number">-70</span>,  <span class="comment"># rotates the x axis labels</span></span><br><span class="line">    leaf_font_size=<span class="number">12</span>  <span class="comment"># font size for the x axis labels</span></span><br><span class="line">)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>]=[<span class="string">&#x27;SimHei&#x27;</span>] <span class="comment">#用来正常显示中文标签</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>]=<span class="literal">False</span> <span class="comment">#用来正常显示负号</span></span><br><span class="line">plt.savefig(re.sub(<span class="string">&#x27;.csv&#x27;</span>,<span class="string">&#x27;&#x27;</span>,file_name)+<span class="string">&#x27;_linkage.png&#x27;</span>)</span><br><span class="line">print(<span class="string">&#x27;Runtime:%d s&#x27;</span>%(datetime.datetime.now()-now_time).seconds)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="/images/%E7%A4%BE%E4%BC%9A%E5%AA%92%E4%BD%93%E8%AE%A1%E7%AE%97/8.png" title="Optional title"></p>
<p>其中，横坐标为知乎用户名，每种的线连起来的用户名代表这些用户的回答可被分为相似的一类。</p>
<p>（看到这里明白为什么只选100个了吧，因为选多了图就画不下了）</p>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>在代码中更改需要爬取的知乎问题的问题id，就可以实现对任意知乎问题下的所有回答内容的上述操作。</p>
<p>代码每次运行都会按照以“问题id+时间”为文件名进行各项文件的保存，不会覆盖之前运行所保留的文件。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><blockquote>
<p>Python网络爬虫实战：爬取知乎话题下 18934 条回答数据-csdn<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/wenxuhonghe/article/details/86515558">https://blog.csdn.net/wenxuhonghe/article/details/86515558</a></p>
</blockquote>
</article><!-- lincense--><div class="post-paginator"><a class="prevSlogan" href="/2021/05/28/Ubuntu16-04%E8%99%9A%E6%8B%9F%E6%9C%BA-Hadoop%EF%BC%9A%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F/" title="Ubuntu16.04虚拟机+Hadoop：伪分布式"><span>< PreviousPost</span><br><span class="prevTitle">Ubuntu16.04虚拟机+Hadoop：伪分布式</span></a><a class="nextSlogan" href="/2021/04/14/%E6%83%B3%E5%88%86%E4%BA%AB%E7%BB%99%E5%88%AB%E4%BA%BA%E7%9C%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BD%B1%E5%83%8F/" title="想分享给别人看的一些影像"><span>NextPost ></span><br><span class="nextTitle">想分享给别人看的一些影像</span></a><div class="clear"></div></div><div id="comment"></div></section></article><footer id="cxo-footer-outer"><div id="cxo-footer-inner"><p class="footer-container"><span>Site by </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span> | theme </span><a target="_blank" rel="noopener" href="https://github.com/Longlongyu/hexo-theme-Cxo"><span>Cxo</span></a></p><i class="fa fa-user"> </i><span id="busuanzi_value_site_uv"></span><span> | </span><i class="fa fa-eye"> </i><span id="busuanzi_value_site_pv"></span></div></footer><!-- catelog--><div class="toc-wrapper" style="top: 70vh;"><div class="toc-catalog"><i class="fa fa-list"> </i><span>CATALOG</span></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%B4%E6%98%8E"><span class="toc-number">2.</span> <span class="toc-text">说明</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A6%81%E6%B1%82"><span class="toc-number">2.1.</span> <span class="toc-text">要求</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">2.2.</span> <span class="toc-text">背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%96%E7%A8%8B%E7%8E%AF%E5%A2%83"><span class="toc-number">2.3.</span> <span class="toc-text">编程环境</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%9F%A5%E4%B9%8E%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86"><span class="toc-number">3.</span> <span class="toc-text">知乎数据采集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%88%AC%E8%99%AB"><span class="toc-number">3.1.</span> <span class="toc-text">数据爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96"><span class="toc-number">3.2.</span> <span class="toc-text">数据读取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.3.</span> <span class="toc-text">数据预处理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%AF%8D%E4%BA%91"><span class="toc-number">4.</span> <span class="toc-text">词云</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#keywords"><span class="toc-number">5.</span> <span class="toc-text">keywords</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90"><span class="toc-number">6.</span> <span class="toc-text">情感分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB"><span class="toc-number">7.</span> <span class="toc-text">聚类</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B6%E4%BB%96"><span class="toc-number">8.</span> <span class="toc-text">其他</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">9.</span> <span class="toc-text">参考</span></a></li></ol></div><!-- top--><i class="fa fa-arrow-up close" id="go-up" aria-hidden="true"></i></body></html>