<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><meta name="author" content="Fy J"><meta name="renderer" content="webkit"><meta name="copyright" content="Fy J"><meta name="keywords" content="MoyangSensei"><meta name="description" content="null"><meta name="Cache-Control" content="no-cache"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><title>论文研读：SISR数据增广的一种新思路 · MoYang</title><link rel="stylesheet" href="/css/style.css?v=2018.7.9"><link rel="stylesheet" href="/css/animation.css?v=2018.7.9"><link rel="icon" href="/img/assets/Moyangico.ico"><link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css?version=1.5.6"><!-- scripts--><script>(function( w ){
  "use strict";
  // rel=preload support test
  if( !w.loadCSS ){
    w.loadCSS = function(){};
  }
  // define on the loadCSS obj
  var rp = loadCSS.relpreload = {};
  // rel=preload feature support test
  // runs once and returns a function for compat purposes
  rp.support = (function(){
    var ret;
    try {
      ret = w.document.createElement( "link" ).relList.supports( "preload" );
    } catch (e) {
      ret = false;
    }
    return function(){
      return ret;
    };
  })();

  // if preload isn't supported, get an asynchronous load by using a non-matching media attribute
  // then change that media back to its intended value on load
  rp.bindMediaToggle = function( link ){
    // remember existing media attr for ultimate state, or default to 'all'
    var finalMedia = link.media || "all";

    function enableStylesheet(){
      link.media = finalMedia;
    }

    // bind load handlers to enable media
    if( link.addEventListener ){
      link.addEventListener( "load", enableStylesheet );
    } else if( link.attachEvent ){
      link.attachEvent( "onload", enableStylesheet );
    }

    // Set rel and non-applicable media type to start an async request
    // note: timeout allows this to happen async to let rendering continue in IE
    setTimeout(function(){
      link.rel = "stylesheet";
      link.media = "only x";
    });
    // also enable media after 3 seconds,
    // which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
    setTimeout( enableStylesheet, 3000 );
  };

  // loop through link elements in DOM
  rp.poly = function(){
    // double check this to prevent external calls from running
    if( rp.support() ){
      return;
    }
    var links = w.document.getElementsByTagName( "link" );
    for( var i = 0; i < links.length; i++ ){
      var link = links[ i ];
      // qualify links to those with rel=preload and as=style attrs
      if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
        // prevent rerunning on link
        link.setAttribute( "data-loadcss", true );
        // bind listeners to toggle media back
        rp.bindMediaToggle( link );
      }
    }
  };

  // if unsupported, run the polyfill
  if( !rp.support() ){
    // run once at least
    rp.poly();

    // rerun poly on an interval until onload
    var run = w.setInterval( rp.poly, 500 );
    if( w.addEventListener ){
      w.addEventListener( "load", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    } else if( w.attachEvent ){
      w.attachEvent( "onload", function(){
        rp.poly();
        w.clearInterval( run );
      } );
    }
  }


  // commonjs
  if( typeof exports !== "undefined" ){
    exports.loadCSS = loadCSS;
  }
  else {
    w.loadCSS = loadCSS;
  }
}( typeof global !== "undefined" ? global : this ) );</script><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" defer></script><script src="/js/main.js?v=2018.7.9" defer></script><!-- fancybox--><link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script><!-- busuanzi--><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta name="generator" content="Hexo 5.1.1"><link rel="alternate" href="/atom.xml" title="MoyangSensei" type="application/atom+xml">
</head><body><section class="profile-close" id="cxo-profile"><div class="profile-avatar"><i class="fa fa-caret-left"></i><img src="/img/assets/cat.png"></div><!--.profile-saying
  i.fa.fa-comment
  .saying--><div class="cxo-profile-inner"><div class="profile-name">Fy J</div><div class="profile-signature">CS专业扫雷学深造学者互联网冲浪一级选手</div><div class="friends"><div>FRIENDS</div><span><a href="//hnjia00.github.io" target="_black">jhn</a></span></div><div class="read-progress"></div></div></section><header id="cxo-intro" style="height: 70vh;background-image: url(/img/intro/index-bg.png);"><nav id="cxo-intro-nav"><section><div class="intro-nav-title"><a href="/">MoYang's Blog</a></div><div class="intro-nav-label-box"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div><i class="fa fa-bars intro-nav-menu"><div class="intro-nav-drop"><a href="/">Home</a><a href="/about/">About</a><a href="/archives/">Archives</a><a href="/tags/">Tags</a></div></i><div class="clear"></div></section></nav><h1 class="post-title">论文研读：SISR数据增广的一种新思路</h1><div class="post-intros"><div class="post-intro-meta"><span class="post-intro-time"><i class="post-intro-calendar fa fa-calendar"></i><span>12-04-2020 20:40:23</span></span><span class="post-intro-tags"><a class="intro-tag fa fa-tag" href="javascript:void(0)" date-tags="论文研读"> 论文研读</a><a class="intro-tag fa fa-tag" href="javascript:void(0)" date-tags="图像超分辨率"> 图像超分辨率</a></span></div><div class="post-intro-read"><span> Word count: <span class="post-count">1.8k</span> | Reading time: <span class="post-count">7</span>min</span></div></div></header><article class="cxo-up" id="cxo-content-outer"><section id="cxo-content-inner"><article class="article-entry" id="post"><blockquote>
<p>原创文章，转载、引用请注明出处！</p>
</blockquote>
<hr>
<blockquote>
<p>Rethinking Data Augmentation for Image Super-resolution: A Comprehensive Analysis and a New Strategy<br>2020 cvpr</p>
</blockquote>
<h1 id="立意"><a href="#立意" class="headerlink" title="立意"></a>立意</h1><p>数据扩充（DA）是在不增加计算成本的情况下提高模型性能的最实用的方法之一。<strong>但现在许多数据增强的方法也都是用于High-level的cv任务，并不适合图像超分辨率任务。</strong></p>
<p>像超分辨率这样的图像恢复研究，非常依赖于合成数据集。最常见的做法是通过模拟系统退化函数（bicubic），可以增加训练样本的数量。但这样的做法欠缺考虑：由于模拟数据分布与实际数据分布之间存在差距，在模拟数据集上训练的模型在实际环境中并没有表现出最佳性能。</p>
<p>这方面的相关工作很少有人做，[24]首先做了这个事情，但不过也就是通过旋转和翻转。也有部分论文提到过这个观点，但是要么就是给出的例子太少，要么就是使用的baseline比较老旧（SRCNN级别的这种）。总之这方面研究还比较稀少。</p>
<blockquote>
<p>[24]Seven ways to improve example-based single image super resolution.<br>2016cvpr</p>
</blockquote>
<p>为了更好地理解低水平视觉中的DA方法，对最初为高级视觉任务开发的各种DA方法的效果进行了全面分析（第2节）。首先根据方法的应用领域将现有的增强技术分为两类：像素域和特征域。当直接应用于SISR时，发现有些方法会损害图像恢复结果，甚至阻碍训练，特别是当一种方法在很大程度上导致相邻像素之间的空间信息丢失或混淆时。</p>
<p>在分析的基础上，提出了CutBlur。<strong>具体做法是：剪切模糊剪切并粘贴LR图像补丁到其对应的真实HR图像补丁，</strong>反之也一样。CurBlur的关键在于让模型不仅知道如何超分，同时也知道哪里需要超分。通过这样的方法，模型能够自适应地去决定图像多大程度上去应用超分而不是盲目地对所有像素进行超分。</p>
<p><img src="/images/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/SISR-DA-NewStrategy/1.png" title="Optional title"></p>
<h1 id="CurBlur"><a href="#CurBlur" class="headerlink" title="CurBlur"></a>CurBlur</h1><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>假设给定LR图像xlr(w<em>h</em>c)和xhr(sw<em>sh</em>c)图像块 [公式] ，其中 [公式] 是放大倍数。由于 CurBlur需要匹配LR图像和HR图像的分辨率，所以会LR图像进行s倍的双三次插值。CurBlur然后就会生成成对的训练样本lr-&gt;hr和hr-&gt;lr ：</p>
<p><img src="/images/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/SISR-DA-NewStrategy/2.png" title="Optional title"></p>
<p>其中，M为二值Mask，用于决定哪里需要被替换掉。</p>
<p>源码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cutblur</span>(<span class="params">im1, im2, prob=<span class="number">1.0</span>, alpha=<span class="number">1.0</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> im1.size() != im2.size():</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;im1 and im2 have to be the same resolution.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> alpha &lt;= <span class="number">0</span> <span class="keyword">or</span> np.random.rand(<span class="number">1</span>) &gt;= prob:</span><br><span class="line">        <span class="keyword">return</span> im1, im2</span><br><span class="line"></span><br><span class="line">    cut_ratio = np.random.randn() * <span class="number">0.01</span> + alpha</span><br><span class="line"></span><br><span class="line">    h, w = im2.size(<span class="number">2</span>), im2.size(<span class="number">3</span>)</span><br><span class="line">    ch, cw = np.int(h*cut_ratio), np.int(w*cut_ratio)</span><br><span class="line">    cy = np.random.randint(<span class="number">0</span>, h-ch+<span class="number">1</span>)</span><br><span class="line">    cx = np.random.randint(<span class="number">0</span>, w-cw+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># apply CutBlur to inside or outside</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> np.random.random() &gt; <span class="number">0.5</span>:</span><br><span class="line">        im2[..., cy:cy+ch, cx:cx+cw] = im1[..., cy:cy+ch, cx:cx+cw]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        im2_aug = im1.clone()</span><br><span class="line">        im2_aug[..., cy:cy+ch, cx:cx+cw] = im2[..., cy:cy+ch, cx:cx+cw]</span><br><span class="line">        im2 = im2_aug</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> im1, im2</span><br></pre></td></tr></table></figure>

<h2 id="为什么CutBlur适用于SR？"><a href="#为什么CutBlur适用于SR？" class="headerlink" title="为什么CutBlur适用于SR？"></a>为什么CutBlur适用于SR？</h2><p>从之前不同DA方法对比，可以看到，图像内容信息的急剧变化，图像块的混叠，或者是丢失像素的相关性都能够损害SR的性能。因此，用于SR的良好的DA方法不应存在不符合实际的模式或信息丢失，并且应该为SR模型良好的正则。</p>
<p>CutBlur能够满足这样的条件：首先，它仅仅在HR和LR图像块之间进行裁剪和粘贴，因此能够最小化边界效应；其次，它可以利用整个图像信息，同时由于样本具有随机的HR比率和位置，CutBlur具有正则化效果。</p>
<blockquote>
<p>CutBlur satisfies these conditions because it performs cut-and-paste between the LR and HR image patches of the same content. By putting the LR (resp. HR) image region onto the corresponding HR (resp. LR) image region, it can minimize the boundary effect, which majorly comes from a mismatch between the image contents (e.g., Cutout and CutMix). Unlike Cutout, CutBlur can utilize the entire image information while it enjoys the regularization effect due to the varied samples of random HR ratios and locations.</p>
</blockquote>
<h2 id="模型从CutBlur中学到了什么？"><a href="#模型从CutBlur中学到了什么？" class="headerlink" title="模型从CutBlur中学到了什么？"></a>模型从CutBlur中学到了什么？</h2><p>与其他DA方法防止分类模型过分自信地做出决策的相似，<strong>CurBlur可以很好地避免SR模型过度锐化图像。</strong></p>
<p><img src="/images/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/SISR-DA-NewStrategy/3.png" title="Optional title"></p>
<p>现在，模型必须同时学习“如何”和“何处”来超分辨率图像，这将导致模型学习“多少”它应该应用超分辨率，这为训练提供了有益的正则化效果。</p>
<blockquote>
<p>When the SR model takes HR images at the test phase, it commonly outputs over-sharpened predictions, especially where the edges are (Figure 2). CutBlur can resolve this issue by directly providing such examples to the model during the training phase. Not only does CutBlur mitigate the over-sharpening problem, but it enhances the SR performance on the other LR regions, thanks to the regularization effect (Figure 3). Note that the residual intensity has significantly decreased in the CutBlur model. We hypothesize that this enhancement comes from constraining the SR model to dis- criminatively apply super-resolution to the image. Now the model has to simultaneously learn both “how” and “where” to super-resolve an image, and this leads the model to learn “how much” it should apply super-resolution, which pro- vides a beneficial regularization effect to the training.</p>
</blockquote>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h2 id="SR模型和数据集的规模影响"><a href="#SR模型和数据集的规模影响" class="headerlink" title="SR模型和数据集的规模影响"></a>SR模型和数据集的规模影响</h2><p><img src="/images/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/SISR-DA-NewStrategy/4.png" title="Optional title"></p>
<h3 id="不同规模的SR模型"><a href="#不同规模的SR模型" class="headerlink" title="不同规模的SR模型"></a>不同规模的SR模型</h3><p><strong>众所周知，一个大模型比一个小模型受益更多。</strong>为了验证这在SR中是否正确，根据模型大小设置不同的扩展应用概率：对于小模型（SRCNN和CARN）p=0.2，对于大模型（RCAN和EDSR），p=1.0。</p>
<p>对于小模型，这个方法没有提供任何好处，或者只是略微提高了性能。这表明了小型模型的严重不拟合，导致DA的影响很小。EDSR规模尚可，因此有所提升。</p>
<h3 id="不同规模的数据集"><a href="#不同规模的数据集" class="headerlink" title="不同规模的数据集"></a>不同规模的数据集</h3><p>减少了用于训练的数据量。使用数据集的50%，10%，和15%。</p>
<p>SRCNN和CARN提升很小或者干脆没有提升。培训时的验证曲线也可以看出这一点（图4a和4b）。RCAN和EDSR提升很大带来了巨大的好处。</p>
<h2 id="不同数据集的比较"><a href="#不同数据集的比较" class="headerlink" title="不同数据集的比较"></a>不同数据集的比较</h2><p>当使用了 CutBlur 对模型进行训练，模型在测试集上的性能得到了明显的提升，尤其是在RealSR数据集上，所有模型至少得到了0.22dB 的提升。而 CARN则能够在 RealSR测试集上达到SOTA性能（RCAN basline），性能与LP-KPN近似，使用参数量仅为LP-KPN的22%。</p>
<p><img src="/images/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/SISR-DA-NewStrategy/5.png" title="Optional title"></p>
<p><img src="/images/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/SISR-DA-NewStrategy/6.png" title="Optional title"></p>
<p><img src="/images/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/SISR-DA-NewStrategy/7.png" title="Optional title"></p>
<h2 id="野外环境下的CutBlur"><a href="#野外环境下的CutBlur" class="headerlink" title="野外环境下的CutBlur"></a>野外环境下的CutBlur</h2><h2 id="其他的一些low-level的视觉任务"><a href="#其他的一些low-level的视觉任务" class="headerlink" title="其他的一些low-level的视觉任务"></a>其他的一些low-level的视觉任务</h2><h1 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h1><p>来自原文叙述的主要贡献：</p>
<ul>
<li><p>To the best of our knowledge, we are the <code>first to provide</code> comprehensive analysis of recent data augmentation methods when directly applied to the SISR task.</p>
</li>
<li><p>We propose a new DA method, CutBlur, which can reduce unrealistic distortions by regularizing a model to learn not only “how” but also “where” to apply the super-resolution to a given image.</p>
</li>
<li><p>Our mixed strategy shows consistent and significant improvements in the SR task, achieving <code>state-of-the-art (SOTA) performance in RealSR</code> [4].</p>
</li>
</ul>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>文章：<br><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yoo_Rethinking_Data_Augmentation_for_Image_Super-resolution_A_Comprehensive_Analysis_and_CVPR_2020_paper.pdf">https://openaccess.thecvf.com/content_CVPR_2020/papers/Yoo_Rethinking_Data_Augmentation_for_Image_Super-resolution_A_Comprehensive_Analysis_and_CVPR_2020_paper.pdf</a></p>
<p>code：<a target="_blank" rel="noopener" href="https://github.com/clovaai/cutblur">https://github.com/clovaai/cutblur</a></p>
<h1 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h1><ul>
<li><p>思路非常的新颖，也许会对目前所做的工作有所启发。</p>
</li>
<li><p>比较简单。</p>
</li>
</ul>
</article><!-- lincense--><div class="post-paginator"><a class="prevSlogan" href="/2020/12/04/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB%EF%BC%9ASISR-DRN/" title="论文研读：SISR-DRN"><span>< PreviousPost</span><br><span class="prevTitle">论文研读：SISR-DRN</span></a><a class="nextSlogan" href="/2020/11/25/Clang-OpenMP%EF%BC%9A%E5%88%9D%E6%AD%A5/" title="Clang+OpenMP：初步"><span>NextPost ></span><br><span class="nextTitle">Clang+OpenMP：初步</span></a><div class="clear"></div></div><div id="comment"></div></section></article><footer id="cxo-footer-outer"><div id="cxo-footer-inner"><p class="footer-container"><span>Site by </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span> | theme </span><a target="_blank" rel="noopener" href="https://github.com/Longlongyu/hexo-theme-Cxo"><span>Cxo</span></a></p><i class="fa fa-user"> </i><span id="busuanzi_value_site_uv"></span><span> | </span><i class="fa fa-eye"> </i><span id="busuanzi_value_site_pv"></span></div></footer><!-- catelog--><div class="toc-wrapper" style="top: 70vh;"><div class="toc-catalog"><i class="fa fa-list"> </i><span>CATALOG</span></div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AB%8B%E6%84%8F"><span class="toc-number">1.</span> <span class="toc-text">立意</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#CurBlur"><span class="toc-number">2.</span> <span class="toc-text">CurBlur</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95"><span class="toc-number">2.1.</span> <span class="toc-text">算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88CutBlur%E9%80%82%E7%94%A8%E4%BA%8ESR%EF%BC%9F"><span class="toc-number">2.2.</span> <span class="toc-text">为什么CutBlur适用于SR？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%BB%8ECutBlur%E4%B8%AD%E5%AD%A6%E5%88%B0%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">2.3.</span> <span class="toc-text">模型从CutBlur中学到了什么？</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">3.</span> <span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#SR%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E8%A7%84%E6%A8%A1%E5%BD%B1%E5%93%8D"><span class="toc-number">3.1.</span> <span class="toc-text">SR模型和数据集的规模影响</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E8%A7%84%E6%A8%A1%E7%9A%84SR%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.1.1.</span> <span class="toc-text">不同规模的SR模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E8%A7%84%E6%A8%A1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.1.2.</span> <span class="toc-text">不同规模的数据集</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8D%E5%90%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-number">3.2.</span> <span class="toc-text">不同数据集的比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8E%E5%A4%96%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84CutBlur"><span class="toc-number">3.3.</span> <span class="toc-text">野外环境下的CutBlur</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E7%9A%84%E4%B8%80%E4%BA%9Blow-level%E7%9A%84%E8%A7%86%E8%A7%89%E4%BB%BB%E5%8A%A1"><span class="toc-number">3.4.</span> <span class="toc-text">其他的一些low-level的视觉任务</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%B4%A1%E7%8C%AE"><span class="toc-number">4.</span> <span class="toc-text">贡献</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B6%E4%BB%96"><span class="toc-number">5.</span> <span class="toc-text">其他</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%84%9F%E6%83%B3"><span class="toc-number">6.</span> <span class="toc-text">感想</span></a></li></ol></div><!-- top--><i class="fa fa-arrow-up close" id="go-up" aria-hidden="true"></i></body></html>